# Lenet-image-processing-asic-accelerator
A high-performance CNN-based image processing accelerator, implemented using a full ASIC flow. Developed in December 2024.

This project presents a custom-designed AI accelerator chip based on the LeNet architecture, targeting image processing tasks. The design was implemented using a full **ASIC flow**, from RTL modeling and logic synthesis to place & route (P&R), and final GDSII generation.

- Supports serial processing of 100 grayscale images (11Ã—11 pixels, 8-bit width)
- Introduced **line buffer** and **sliding convolution window**, reducing register count from **169 to 44** (a 75% reduction), significantly optimizing area and P&R complexity
- Computation core adopts a **three-stage pipeline** (Multiply â†’ Add â†’ Quantize) to boost operating frequency
- Leveraged **cycle-level reuse** of convolution kernels and MAC units for extreme area efficiency
- Achieved performance about **6Ã— faster** than comparable designs (294â€¯MHz vs. 50â€¯MHz), with a compact core area of only **0.2â€¯mmÂ²**
- Fabricated using **SMIC 0.18â€¯Âµm CMOS technology**
- Final project score: **99/100 (Highest in school history)**

> Developed in December 2024.

---

## ğŸ§° Tools Used

This project was developed using a full ASIC design toolchain, including:

- **Vim** â€“ RTL development and editing  
- **Synopsys VCS** â€“ Functional simulation  
- **Synopsys DVE** â€“ Waveform viewing and debugging  
- **Design Compiler (DC)** â€“ Logic synthesis  
- **Formality** â€“ RTL and netlist equivalence checking  
- **IC Compiler (ICC)** â€“ Place and route  
- **Cadence tools** â€“ Supporting backend design and analysis (as needed)

---

## ğŸ“œ License

This project is released under the [MIT License](LICENSE).  
You are free to use, modify, and distribute the code with proper attribution.

---

## ğŸ™ Acknowledgements

We sincerely thank all project team members for their dedication and contributions:

- **Z. Li**, **Z. Xu**, **J. Deng**, **M. Kuang**

We also gratefully acknowledge the guidance and support from:

- **Y. W.**, **S. Li**, **Junkai Wang**, **Xuesong Qi**, **Haoyu Zheng**
